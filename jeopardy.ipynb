{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Winning Jeopardy: a statistical analysis\n",
    "\n",
    "Jeopardy is a popular US TV show in which participant answer questions for a chance to win money. It has run for many decades and it has become a major force in popular culture.\n",
    "\n",
    "In this notebook we perform a statistical analysis of a dataset containing 20000 Jeopardy questions to determine if it is possible to gain an advantage. The data we will use is a sample from the full dataset containing 200000 questions. That can be found [here](https://www.reddit.com/r/datasets/comments/1uyd0t/200000_jeopardy_questions_in_a_json_file/). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Show Number</th>\n",
       "      <th>Air Date</th>\n",
       "      <th>Round</th>\n",
       "      <th>Category</th>\n",
       "      <th>Value</th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>HISTORY</td>\n",
       "      <td>$200</td>\n",
       "      <td>For the last 8 years of his life, Galileo was ...</td>\n",
       "      <td>Copernicus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>ESPN's TOP 10 ALL-TIME ATHLETES</td>\n",
       "      <td>$200</td>\n",
       "      <td>No. 2: 1912 Olympian; football star at Carlisl...</td>\n",
       "      <td>Jim Thorpe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>EVERYBODY TALKS ABOUT IT...</td>\n",
       "      <td>$200</td>\n",
       "      <td>The city of Yuma in this state has a record av...</td>\n",
       "      <td>Arizona</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>THE COMPANY LINE</td>\n",
       "      <td>$200</td>\n",
       "      <td>In 1963, live on \"The Art Linkletter Show\", th...</td>\n",
       "      <td>McDonald's</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>EPITAPHS &amp; TRIBUTES</td>\n",
       "      <td>$200</td>\n",
       "      <td>Signer of the Dec. of Indep., framer of the Co...</td>\n",
       "      <td>John Adams</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Show Number    Air Date      Round                         Category  Value  \\\n",
       "0         4680  2004-12-31  Jeopardy!                          HISTORY   $200   \n",
       "1         4680  2004-12-31  Jeopardy!  ESPN's TOP 10 ALL-TIME ATHLETES   $200   \n",
       "2         4680  2004-12-31  Jeopardy!      EVERYBODY TALKS ABOUT IT...   $200   \n",
       "3         4680  2004-12-31  Jeopardy!                 THE COMPANY LINE   $200   \n",
       "4         4680  2004-12-31  Jeopardy!              EPITAPHS & TRIBUTES   $200   \n",
       "\n",
       "                                            Question      Answer  \n",
       "0  For the last 8 years of his life, Galileo was ...  Copernicus  \n",
       "1  No. 2: 1912 Olympian; football star at Carlisl...  Jim Thorpe  \n",
       "2  The city of Yuma in this state has a record av...     Arizona  \n",
       "3  In 1963, live on \"The Art Linkletter Show\", th...  McDonald's  \n",
       "4  Signer of the Dec. of Indep., framer of the Co...  John Adams  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jeopardy = pd.read_csv('jeopardy.csv')\n",
    "jeopardy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Show Number', ' Air Date', ' Round', ' Category', ' Value',\n",
       "       ' Question', ' Answer'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jeopardy.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Show Number', 'Air Date', 'Round', 'Category', 'Value', 'Question',\n",
       "       'Answer'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jeopardy.columns = jeopardy.columns.str.strip()\n",
    "jeopardy.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalizing the columns\n",
    "\n",
    "Before performing our analysis, we will normalize the question and answer columns by removing uppercases and punctuations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def norm_string(string):\n",
    "    return (string\n",
    "            .lower()\n",
    "            .replace(',', '')\n",
    "            .replace('.', '')\n",
    "            .replace(':', '')\n",
    "            .replace(';', '')\n",
    "            .replace('\"', '')\n",
    "            .replace(\"'\", '')\n",
    "            .replace('!', '')\n",
    "            .replace('?', '')\n",
    "           )    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "jeopardy['clean_question'] = jeopardy['Question'].apply(norm_string)\n",
    "jeopardy['clean_answer'] = jeopardy['Answer'].apply(norm_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we normalize the _Value_ column and the _Air Date_ column. We convert the _Value_ column to numeric values and the _Air Date_ column to datetime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def norm_dollars(string):\n",
    "    norm_string = string.replace('$', '')\n",
    "    try:\n",
    "        norm_string = int(norm_string)\n",
    "    except:\n",
    "        norm_string = 0\n",
    "    return norm_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "jeopardy['clean_value'] = jeopardy['Value'].apply(norm_dollars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "jeopardy['Air Date'] = pd.to_datetime(jeopardy['Air Date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of Jeopardy questions\n",
    "\n",
    "We are now interested in finding:\n",
    "* How often is the answer deducible from the question\n",
    "* How often new questions are repeats of older questions\n",
    "\n",
    "This will give a guideline on how much time should be spent on studying previous questions.\n",
    "\n",
    "## Is the answer contained in the question?\n",
    "\n",
    "We begin by answering the first question. Our approach will be to study how many times words in the answer also occur in the question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def question_analysis(row):\n",
    "    split_answer = row['clean_answer'].split(' ')\n",
    "    split_question = row['clean_question'].split(' ')\n",
    "    match_count = 0\n",
    "    split_answer = [y for y in split_answer if y != 'the']\n",
    "    try:\n",
    "        for item in split_answer:\n",
    "            match_count += int(item in split_question)\n",
    "        return match_count/len(split_answer)\n",
    "    \n",
    "    except:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "jeopardy['answer_in_question'] = jeopardy.apply(question_analysis, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05548872307085218"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jeopardy['answer_in_question'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    19999.000000\n",
       "mean         0.055489\n",
       "std          0.161427\n",
       "min          0.000000\n",
       "25%          0.000000\n",
       "50%          0.000000\n",
       "75%          0.000000\n",
       "max          1.000000\n",
       "Name: answer_in_question, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jeopardy['answer_in_question'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "\n",
    "We have found that on average ~0.05 words in the answer are contained in the questions. We have also seen that the maximum is 1, so we can safely assume that if one word from the answer is contained in the question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How often are questions repeats of older questions?\n",
    "\n",
    "We now investigate how often the questions proposed are repeats of older Jeopardy questions. To answer this, we will check for each question how many times the words in the question that longer than 6 characters have appeared previously. This is a good proxy for answering our original question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "question_overlap = []\n",
    "terms_used = set()\n",
    "\n",
    "for index, row in jeopardy.iterrows():\n",
    "    split_question = row['clean_question'].split(' ')\n",
    "    split_question = [y for y in split_question if len(y)>5]\n",
    "    \n",
    "    match_count = 0\n",
    "    if len(split_question)>0:    \n",
    "        for word in split_question:\n",
    "            match_count += int(word in terms_used)\n",
    "        for word in split_question:\n",
    "            terms_used.add(word)\n",
    "        question_overlap.append(match_count / len(split_question))\n",
    "    else:\n",
    "        question_overlap.append(match_count)\n",
    "\n",
    "jeopardy['question_overlap'] = question_overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    19999.000000\n",
       "mean         0.685725\n",
       "std          0.299306\n",
       "min          0.000000\n",
       "25%          0.500000\n",
       "50%          0.750000\n",
       "75%          1.000000\n",
       "max          1.000000\n",
       "Name: question_overlap, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jeopardy['question_overlap'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.000000    30.546527\n",
       "0.500000    10.885544\n",
       "0.666667    10.070504\n",
       "0.000000     7.960398\n",
       "0.750000     7.695385\n",
       "0.800000     6.140307\n",
       "0.600000     4.380219\n",
       "0.833333     4.110206\n",
       "0.333333     3.815191\n",
       "0.400000     2.195110\n",
       "Name: question_overlap, dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute percentages of value counts\n",
    "jeopardy['question_overlap'].value_counts(normalize=True).apply(lambda x: x*100).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "\n",
    "We have show that a large number of questions are recycled. More precisely:\n",
    "* ~30% of questions are completely recycled\n",
    "* ~8% of questions are completely new\n",
    "* 75% of questions have at least a 50% overlap with an old question.\n",
    "\n",
    "From this analysis we conclude that studying the past questions is most definitely a winning strategy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Typical words in high-value questions\n",
    "\n",
    "Next we study which words are more likely to appear in high-value questions. To do this, we first split questions in two categories, depending on their value:\n",
    "\n",
    "* Low value: Value < 800\n",
    "* High value: Value >= 800\n",
    "\n",
    "This will give us the proportion of low-value and high-value questions. For each word, we multiply the total number of occurences by the two proportions above to obtain the expected number of occurences in low-value and high-value questions respectively. We can compare these expected numbers with the actual occurences and test for statistical significance of the difference with a Chi-squared test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def classify_value(row):\n",
    "    if row['clean_value'] >= 800:\n",
    "        return 1\n",
    "    elif row['clean_value'] < 800:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "jeopardy['high_value'] = jeopardy.apply(classify_value, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def low_high_value_count(word):\n",
    "    low_count = 0\n",
    "    high_count = 0\n",
    "    for index, row in jeopardy.iterrows():\n",
    "        question_split = row['clean_question'].split(' ')\n",
    "        if word in question_split:\n",
    "            high_count += row['high_value']\n",
    "            low_count += 1 - row['high_value']\n",
    "    return low_count, high_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abbreviating',\n",
       " 'haunts',\n",
       " 'cinchers',\n",
       " 'boosters',\n",
       " 'abusive',\n",
       " 'blinked',\n",
       " 'bullets',\n",
       " 'grovers',\n",
       " 'joseph',\n",
       " 'auburns',\n",
       " 'simulator',\n",
       " 'unable',\n",
       " 'reformed',\n",
       " 'jack-jack',\n",
       " 'mozarts',\n",
       " 'infant',\n",
       " 'olenska',\n",
       " 'prescriptions',\n",
       " 'corcoran</a>)',\n",
       " 'cleavers']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observed_expected = []\n",
    "comparison_terms = list(terms_used)[:20]\n",
    "comparison_terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 0),\n",
       " (2, 1),\n",
       " (1, 0),\n",
       " (2, 0),\n",
       " (1, 0),\n",
       " (0, 1),\n",
       " (0, 2),\n",
       " (0, 1),\n",
       " (24, 10),\n",
       " (1, 0),\n",
       " (2, 0),\n",
       " (1, 1),\n",
       " (0, 1),\n",
       " (0, 1),\n",
       " (0, 1),\n",
       " (3, 0),\n",
       " (1, 0),\n",
       " (1, 0),\n",
       " (1, 0),\n",
       " (0, 1)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for term in comparison_terms:\n",
    "    observed_expected.append(low_high_value_count(term))\n",
    "observed_expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "high_value_count = len(jeopardy[jeopardy['high_value'] == 1])\n",
    "low_value_count = len(jeopardy[jeopardy['high_value'] == 0])\n",
    "chi_squared = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.stats import chisquare\n",
    "\n",
    "for item in observed_expected:\n",
    "    total = sum(item)\n",
    "    total_prop = total/jeopardy.shape[0]\n",
    "    \n",
    "    expected_high_count = total_prop * high_value_count\n",
    "    expected_low_count = total_prop * low_value_count\n",
    "    expected = [expected_low_count, expected_high_count]\n",
    "    \n",
    "    chi_squared.append(chisquare(f_obs=item, f_exp=expected))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Power_divergenceResult(statistic=0.6600813480534574, pvalue=0.41653122582698476),\n",
       " Power_divergenceResult(statistic=0.05176339364874122, pvalue=0.8200227626475018),\n",
       " Power_divergenceResult(statistic=0.6600813480534574, pvalue=0.41653122582698476),\n",
       " Power_divergenceResult(statistic=1.3201626961069148, pvalue=0.2505628539124093),\n",
       " Power_divergenceResult(statistic=0.6600813480534574, pvalue=0.41653122582698476),\n",
       " Power_divergenceResult(statistic=1.5149647887323945, pvalue=0.2183830639074722),\n",
       " Power_divergenceResult(statistic=3.029929577464789, pvalue=0.0817415642907401),\n",
       " Power_divergenceResult(statistic=1.5149647887323945, pvalue=0.2183830639074722),\n",
       " Power_divergenceResult(statistic=1.5206863338832604, pvalue=0.21751566001383427),\n",
       " Power_divergenceResult(statistic=0.6600813480534574, pvalue=0.41653122582698476),\n",
       " Power_divergenceResult(statistic=1.3201626961069148, pvalue=0.2505628539124093),\n",
       " Power_divergenceResult(statistic=0.08752306839292578, pvalue=0.7673499986093351),\n",
       " Power_divergenceResult(statistic=1.5149647887323945, pvalue=0.2183830639074722),\n",
       " Power_divergenceResult(statistic=1.5149647887323945, pvalue=0.2183830639074722),\n",
       " Power_divergenceResult(statistic=1.5149647887323945, pvalue=0.2183830639074722),\n",
       " Power_divergenceResult(statistic=1.9802440441603721, pvalue=0.1593646995918191),\n",
       " Power_divergenceResult(statistic=0.6600813480534574, pvalue=0.41653122582698476),\n",
       " Power_divergenceResult(statistic=0.6600813480534574, pvalue=0.41653122582698476),\n",
       " Power_divergenceResult(statistic=0.6600813480534574, pvalue=0.41653122582698476),\n",
       " Power_divergenceResult(statistic=1.5149647887323945, pvalue=0.2183830639074722)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chi_squared"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "\n",
    "We cannot conclude that any of the words in our small sample is significantly more likely to appear either in low- or high-value questions. A full analysis including all words should be performerd, but such analysis will necessarily incur in many Type I errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
